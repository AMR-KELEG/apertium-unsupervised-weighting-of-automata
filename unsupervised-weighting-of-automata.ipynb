{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the tagged corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-04 23:11:30--  https://raw.githubusercontent.com/apertium/apertium-eng/master/texts/eng.tagged\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.240.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.240.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 645001 (630K) [text/plain]\n",
      "Saving to: ‘eng.tagged’\n",
      "\n",
      "eng.tagged          100%[===================>] 629.88K   199KB/s    in 3.2s    \n",
      "\n",
      "2019-04-04 23:11:34 (199 KB/s) - ‘eng.tagged’ saved [645001/645001]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://raw.githubusercontent.com/apertium/apertium-eng/master/texts/eng.tagged && mv eng.tagged data/eng.tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/eng.tagged', 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['^Politics/politics<n><sg>$\\n',\n",
       " '^in/in<pr>$\\n',\n",
       " '^Afghanistan/Afghanistan<np><top><sg>$\\n',\n",
       " '^has/have<vbhaver><pres><p3><sg>$\\n',\n",
       " '^historically/historically<adv>$\\n',\n",
       " '^consisted/consist<vblex><pp>$\\n',\n",
       " '^of/of<pr>$\\n',\n",
       " '^power/power<n><sg>$\\n',\n",
       " '^struggles/struggle<n><pl>$\\n',\n",
       " '^,/,<cm>$\\n',\n",
       " '^bloody/*bloody$\\n',\n",
       " '^coups/coup<n><pl>$\\n',\n",
       " '^and/and<cnjcoo>$\\n',\n",
       " '^unstable/unstable<adj>$\\n',\n",
       " '^transfers/transfer<n><pl>$\\n',\n",
       " '^of/of<pr>$\\n',\n",
       " '^power/power<n><sg>$\\n',\n",
       " '^./.<sent>$\\n',\n",
       " '^With/with<pr>$\\n',\n",
       " '^the/the<det><def><sp>$\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Politics in Afghanistan has historically consisted of power struggles , bloody coups and unstable transfers of power .'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([l[1:l.find('/')] for l in lines[:18]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def split_X_y(file_lines):\n",
    "    'With/with<pr>$'\n",
    "    splitted_lines = [line[1:].strip().split('/') for line in file_lines]\n",
    "    splitted_lines = [line for line in splitted_lines if line[0]]\n",
    "\n",
    "    tokens = [l[0] for l in splitted_lines]\n",
    "    targets = [l[1][:-1] for l in splitted_lines]\n",
    "    return pd.DataFrame({\n",
    "        'token': tokens,\n",
    "        'target': targets\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = split_X_y(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29650 entries, 0 to 29649\n",
      "Data columns (total 2 columns):\n",
      "token     29650 non-null object\n",
      "target    29650 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 463.4+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token     0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [TODO] Remove the stopwords from the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the sentences into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(corpus_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11909</th>\n",
       "      <td>millionaires</td>\n",
       "      <td>millionaire&lt;n&gt;&lt;pl&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>rate</td>\n",
       "      <td>rate&lt;n&gt;&lt;sg&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10299</th>\n",
       "      <td>interrupter</td>\n",
       "      <td>*interrupter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>.</td>\n",
       "      <td>.&lt;sent&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15046</th>\n",
       "      <td>and</td>\n",
       "      <td>and&lt;cnjcoo&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              token              target\n",
       "11909  millionaires  millionaire<n><pl>\n",
       "1827           rate         rate<n><sg>\n",
       "10299   interrupter        *interrupter\n",
       "640               .             .<sent>\n",
       "15046           and         and<cnjcoo>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25628</th>\n",
       "      <td>of</td>\n",
       "      <td>of&lt;pr&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7249</th>\n",
       "      <td>frustrated</td>\n",
       "      <td>frustrate&lt;vblex&gt;&lt;pp&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>following</td>\n",
       "      <td>follow&lt;vblex&gt;&lt;ger&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8164</th>\n",
       "      <td>,</td>\n",
       "      <td>,&lt;cm&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26082</th>\n",
       "      <td>otherwise</td>\n",
       "      <td>otherwise&lt;adv&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            token                target\n",
       "25628          of                of<pr>\n",
       "7249   frustrated  frustrate<vblex><pp>\n",
       "9043    following    follow<vblex><ger>\n",
       "8164            ,                 ,<cm>\n",
       "26082   otherwise        otherwise<adv>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis</th>\n",
       "      <th>count</th>\n",
       "      <th>log_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the&lt;det&gt;&lt;def&gt;&lt;sp&gt;</td>\n",
       "      <td>1862</td>\n",
       "      <td>2.662450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,&lt;cm&gt;</td>\n",
       "      <td>1475</td>\n",
       "      <td>2.895444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.&lt;sent&gt;</td>\n",
       "      <td>1031</td>\n",
       "      <td>3.253572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of&lt;pr&gt;</td>\n",
       "      <td>930</td>\n",
       "      <td>3.356672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and&lt;cnjcoo&gt;</td>\n",
       "      <td>704</td>\n",
       "      <td>3.635079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            analysis  count  log_prob\n",
       "0  the<det><def><sp>   1862  2.662450\n",
       "1              ,<cm>   1475  2.895444\n",
       "2            .<sent>   1031  3.253572\n",
       "3             of<pr>    930  3.356672\n",
       "4        and<cnjcoo>    704  3.635079"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unigrams_counts = train_df['target'].value_counts().reset_index()\n",
    "unigrams_counts.columns = ['analysis', 'count']\n",
    "unigrams_counts['log_prob'] = -np.log(unigrams_counts['count']/(train_df.shape[0]))\n",
    "unigrams_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict = pd.Series(unigrams_counts.log_prob.values, index=unigrams_counts.analysis).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Apertium's analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "import subprocess\n",
    "def get_apertium_analyses(token):\n",
    "    #TODO: Don't use shell=True\n",
    "    analyses = subprocess.run(\n",
    "        ['echo {} | apertium-destxt | lt-proc {}'.format(token,\n",
    "                                                         settings.APERTIUM_ANALYZER_BIN_LOC)],\n",
    "        stdout=subprocess.PIPE,\n",
    "        shell=True).stdout.decode()\n",
    "\n",
    "    return analyses[analyses.find('/') + 1: analyses.find('$')].split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['store<n><pl>', 'store<vblex><pres><p3><sg>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_apertium_analyses('stores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rank the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_analyses(token):\n",
    "    '''The first tag is the most probable one'''\n",
    "    analyses = get_apertium_analyses(token)\n",
    "    \n",
    "    analyses_prob = [(prob_dict.get(analysis, np.inf), analysis) for analysis in analyses]\n",
    "    analyses_prob.sort()\n",
    "    \n",
    "    return analyses_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(inf, 'zinc<n><sg>')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_analyses(test_df.sample().loc[:, 'token'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the one symbol tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_symbols_from_target(target):\n",
    "    return '\\t'.join(re.findall(r'<.+?>', target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<det>', '<def>', '<sp>', '<cm>', '<sent>']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_symbol_tokens = pd.Series('\\t'.join(unigrams_counts['analysis'].apply(get_symbols_from_target)).split('\\t')).unique()\n",
    "one_symbol_tokens = [sym for sym in one_symbol_tokens if sym]\n",
    "one_symbol_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fst_input_data/one_sym', 'w') as f:\n",
    "    f.write('\\n'.join(one_symbol_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the string pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_to_stringpair(row):\n",
    "    return '{}:{}\\t{}'.format(row['token'].replace(':', '\\:'), row['target'].replace(':', '\\:'), prob_dict.get(row['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pairs = train_df.drop_duplicates().apply(tuple_to_stringpair, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fst_input_data/str_pairs', 'w') as f:\n",
    "    f.write('\\n'.join(string_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a new hfst weighted transducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hfst-strings2fst -i fst_input_data/str_pairs -o bin/hfst_model -j -m fst_input_data/one_sym'], returncode=0, stdout=b'')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "        ['hfst-strings2fst -i {} -o {} -j -m {}'.format('fst_input_data/str_pairs',\n",
    "                                                        'bin/hfst_model',\n",
    "                                                        'fst_input_data/one_sym')],\n",
    "        stdout=subprocess.PIPE,\n",
    "        shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert hfst transducer to att format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hfst-fst2txt -i bin/hfst_model -o fst_input_data/letters.att'], returncode=0, stdout=b'')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "        ['hfst-fst2txt -i {} -o {}'.format('bin/hfst_model', 'fst_input_data/letters.att')],\n",
    "        stdout=subprocess.PIPE,\n",
    "        shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a new weighted transducer from att format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['lt-comp lr fst_input_data/letters.att bin/apert_model'], returncode=0, stdout=b'main@standard 34369 34368\\nfinal@inconditional 29 28\\n')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(\n",
    "        ['lt-comp lr {} {}'.format('fst_input_data/letters.att', 'bin/apert_model')],\n",
    "        stdout=subprocess.PIPE,\n",
    "        shell=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate analysis from new weighted transducer\n",
    "Note: You will need to build the master branch of lttoolbox so that the analyses weights are computed correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "import subprocess\n",
    "def get_apertium_analyses(token):\n",
    "    #TODO: Don't use shell=True\n",
    "    analyses = subprocess.run(\n",
    "        ['echo {} | apertium-destxt | ../lttoolbox/lttoolbox/lt-proc {} -W'.format(token,\n",
    "                                                         'bin/apert_model')],\n",
    "        stdout=subprocess.PIPE,\n",
    "        shell=True).stdout.decode()\n",
    "\n",
    "    return analyses[analyses.find('/') + 1: analyses.find('$')].split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do<vblex><pres><W:9.498710>',\n",
       " 'do<vbdo><pres><W:9.498710>',\n",
       " 'do<vblex><inf><W:10.191857>']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_apertium_analyses('do')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
